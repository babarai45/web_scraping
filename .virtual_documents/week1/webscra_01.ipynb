





# import libraries
from bs4 import BeautifulSoup
import requests


url = 'https://www.techtarget.com/searchbusinessanalytics/definition/data-mining#:~:text=Data%20mining%20is%20the%20process,make%20more%20informed%20business%20decisions.'


response = requests.get(url)


print(response.status_code)   # to check status code of connectivity


soup = BeautifulSoup(response.text, 'html.parser')


print(soup.prettify()) # print the parsed data of html page in a readable format 


soup.title # print the title of the page


soup.find_all('p') # print all the paragraphs of the page


soup.find_all('a') # print all the hyperlinks of the page


soup.find(text='data mining') # print the first text of the page


soup.find_all('a')[3].get('href') # print the first hyperlink of the page


# %pip install lxml
soup = BeautifulSoup("<tag1>a<tag2/>bad<tag3>html", "html") # parse the xml data


soup.get_text() # print the text of the xml data


soup.get_attribute_list('') # print the attribute list of the tag1


soup.fi

































































# all methods of BeautifulSoup
#-1 =  print all the methods of BeautifulSoup



# all methods of Tag
#-1 =  title = soup.title
#-2 =  h1 = soup.h1
#-3 =  h1.name (name of the tag) like h1


soup.find_all('h1') # print all the h1 tags of the page


# now exatract the data from the page using the tags



import pandas as pd 



# create a dataframe
data = {
    'Name': ['Tom', 'Nick', 'John'],
    'Age': [20, 21, 19]
}


data = pd.DataFrame(data)


data


url2 ='https://www.pharmaceutical-technology.com/news/india-covid-19-coronavirus-updates-status-by-state/?cf-view&cf-closed'


response2 = requests.get(url2)


print(response2.status_code)


soup2 = BeautifulSoup(response2.text, 'html.parser')


print(soup2.prettify())



